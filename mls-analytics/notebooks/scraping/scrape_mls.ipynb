{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295286d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import os\n",
    "import time\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032740bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--force-device-scale-factor=1\")\n",
    "\n",
    "    # Look human\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    options.add_argument(\n",
    "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "    \"source\": \"Object.defineProperty(navigator,'webdriver',{get:()=>undefined})\"\n",
    "    })\n",
    "    \n",
    "    return driver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f20ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_team_blocks(driver):\n",
    "\n",
    "    section = driver.find_element(\n",
    "        By.CSS_SELECTOR,\n",
    "        \"div.mls-c-stats.mls-c-stats--match-hub-player-stats\"\n",
    "    )\n",
    "\n",
    "    elems = section.find_elements(By.XPATH, \"./*\")\n",
    "\n",
    "    teams = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(elems):\n",
    "\n",
    "        el = elems[i]\n",
    "\n",
    "        if \"mls-c-stats__club-abbreviation\" in el.get_attribute(\"class\"):\n",
    "            team = el.text.strip()\n",
    "\n",
    "            main = None\n",
    "            gk = None\n",
    "\n",
    "            j = i + 1\n",
    "            while j < len(elems):\n",
    "                if \"mls-c-stats__table\" in elems[j].get_attribute(\"class\"):\n",
    "                    main = elems[j].find_element(By.CSS_SELECTOR, \"table\")\n",
    "                    break\n",
    "                j += 1\n",
    "\n",
    "            j = j + 1\n",
    "            while j < len(elems):\n",
    "                if \"mls-o-match-hub-container__mt-25\" in elems[j].get_attribute(\"class\"):\n",
    "                    gk = elems[j].find_element(By.CSS_SELECTOR, \"table\")\n",
    "                    break\n",
    "                j += 1\n",
    "\n",
    "            teams.append({\n",
    "                \"team\": team,\n",
    "                \"main\": main,\n",
    "                \"gk\": gk\n",
    "            })\n",
    "\n",
    "            i = j\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc0452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_match_id(data, match_id):\n",
    "    if isinstance(data, list):\n",
    "        return [dict(item, match_id=match_id) for item in data]\n",
    "    elif isinstance(data, dict):\n",
    "        return dict(data, match_id=match_id)\n",
    "    elif hasattr(data, \"assign\"):  # pandas DataFrame\n",
    "        return data.assign(match_id=match_id)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f27e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_table(table_el):\n",
    "    rows = []\n",
    "\n",
    "    header_cells = table_el.find_elements(By.CSS_SELECTOR, \"thead .mls-o-table__header\")\n",
    "    headers = [h.text.strip() for h in header_cells]\n",
    "\n",
    "    for tr in table_el.find_elements(By.CSS_SELECTOR, \"tbody .mls-o-table__row\"):\n",
    "        cells = tr.find_elements(By.CSS_SELECTOR, \".mls-o-table__cell\")\n",
    "        values = [c.text.strip() for c in cells]\n",
    "\n",
    "        if len(values) < len(headers):\n",
    "            values += [\"\"] * (len(headers) - len(values))\n",
    "        elif len(values) > len(headers):\n",
    "            values = values[:len(headers)]\n",
    "\n",
    "        rows.append(dict(zip(headers, values)))\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee5446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feed(driver, link, match_id):\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    driver.get(link)\n",
    "    feed = []\n",
    "    date = ''\n",
    "    \n",
    "    try:\n",
    "        date = driver.find_element(By.XPATH, \"//div[contains(@class, 'mls-c-blockheader__subtitle')]\").text.strip()\n",
    "        feed_button = driver.find_element(By.XPATH,\n",
    "                            \"//*[normalize-space(text())='Feed']\")\n",
    "\n",
    "        feed_button.click()\n",
    "        \n",
    "        utils.js_scroll_by(driver, 900)\n",
    "\n",
    "        utils.js_scroll_by(driver, 3000)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, \"//*[normalize-space(text())='First half begins.']\")))\n",
    "\n",
    "        first_half = driver.find_element(By.XPATH, \"//*[normalize-space(text())='First half begins.']\")\n",
    "\n",
    "        utils.js_scroll_into_view(driver, first_half)\n",
    "        if not first_half:\n",
    "            print(f\"First half element not found for link {link}\")\n",
    "        try:            \n",
    "            cont = driver.find_element(By.CSS_SELECTOR, 'div[class=\"mls-o-match-feed\"]')\n",
    "\n",
    "            events = cont.find_elements(By.CSS_SELECTOR, 'div[class=\"mls-o-match-feed__container\"]')\n",
    "\n",
    "            for event in events:\n",
    "                minute_el = event.find_elements(\n",
    "                    By.CSS_SELECTOR, \n",
    "                    \".mls-o-match-feed__regular-time, .mls-o-match-feed__minute\"\n",
    "                    )\n",
    "                minute = minute_el[0].text.strip() if minute_el else None\n",
    "\n",
    "                title_el = event.find_elements(By.CSS_SELECTOR, \".mls-o-match-feed__title\")\n",
    "                title = title_el[0].text.strip() if title_el else None\n",
    "\n",
    "                comment_el = event.find_elements(By.CSS_SELECTOR, \".mls-o-match-feed__comment\")\n",
    "                comment = comment_el[0].text.strip() if comment_el else None\n",
    "                \n",
    "                players_wrap = event.find_elements(By.XPATH, \".//*[contains(@class,'mls-o-match-feed__players')]\")\n",
    "\n",
    "                out_player = None\n",
    "                in_player = None\n",
    "\n",
    "                if players_wrap:\n",
    "                    out_nodes = players_wrap[0].find_elements(\n",
    "                        By.CSS_SELECTOR, \".mls-o-match-feed__sub-out .mls-o-match-feed__player\"\n",
    "                    )\n",
    "                    in_nodes = players_wrap[0].find_elements(\n",
    "                        By.CSS_SELECTOR, \".mls-o-match-feed__sub-in .mls-o-match-feed__player\"\n",
    "                    )\n",
    "\n",
    "                    out_player = out_nodes[0].text.strip() if out_nodes and out_nodes[0].text.strip() else None\n",
    "                    in_player  = in_nodes[0].text.strip()  if in_nodes and in_nodes[0].text.strip()  else None\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                feed.append({\n",
    "                    'match_id': match_id,\n",
    "                    'date': date,\n",
    "                    'minute': minute,\n",
    "                    'title': title,\n",
    "                    'comment': comment,\n",
    "                    'out_player': out_player,\n",
    "                    'in_player': in_player\n",
    "                })\n",
    "                if not feed:\n",
    "                    print(f\"No feed events found for link {link}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting feed events for link {link}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting feed for link {link}: {e}\")\n",
    "    return pd.DataFrame(feed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dde135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stats(driver, link, match_id):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    driver.get(link)\n",
    "    \n",
    "    general_stats = []\n",
    "    shooting_stats = []\n",
    "    passing_stats = []\n",
    "    possession_stats = []\n",
    "    xg_stats = []\n",
    "    date = ''\n",
    "    \n",
    "    main_body = driver.find_element(By.TAG_NAME, 'main')\n",
    "    stats_bttn = main_body.find_element(By.LINK_TEXT, 'Stats')\n",
    "\n",
    "    try:\n",
    "        date = driver.find_element(By.XPATH, \"//div[contains(@class, 'mls-c-blockheader__subtitle')]\").text.strip()\n",
    "        stats_bttn.click()\n",
    "\n",
    "        try:\n",
    "            general_cont = wait.until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,\n",
    "                    '//section[contains(@class,\"mls-l-module--stats-comparison\")'\n",
    "                    ' and contains(@class,\"mls-l-module--general\")'\n",
    "                    ' and not(contains(@style,\"display: none\"))]')))\n",
    "\n",
    "\n",
    "            utils.js_scroll_into_view(driver, general_cont)\n",
    "            general_cards = utils.scrape_cards(general_cont, driver)\n",
    "\n",
    "            for it in general_cards:\n",
    "                general_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping general stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            clubs_wrap = wait.until(\n",
    "                EC.visibility_of_element_located((\n",
    "                    By.XPATH,\n",
    "                    '//section[contains(@class,\"d3-l-section-row\")][@data-toggle=\"clubs\" and not(contains(@style,\"display: none\"))]'\n",
    "                )))\n",
    "\n",
    "            shooting_cont = clubs_wrap.find_element(\n",
    "                By.XPATH,\n",
    "                './/section[contains(@class,\"mls-l-module--shooting-breakdown\")]'\n",
    "            )\n",
    "\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView({block:'center'});\",\n",
    "                shooting_cont)\n",
    "\n",
    "            shooting_cards = utils.scrape_cards(shooting_cont, driver)\n",
    "\n",
    "            for it in shooting_cards:\n",
    "                shooting_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping shooting stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            passing_cont = driver.find_element(By.XPATH, '//section[contains(@class,\"passing-breakdown\")]')\n",
    "\n",
    "            passing_cards = utils.scrape_cards(passing_cont, driver)\n",
    "            for it in passing_cards:\n",
    "                passing_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping passing stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            possession_cont = driver.find_element(By.XPATH, '//section[contains(@class,\"--possession\")]')\n",
    "            bar_cont = possession_cont.find_element(By.XPATH, './/*[contains(@class,\"mls-o-possession__intervals\")]')\n",
    "\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView({block:'center'});\",\n",
    "                bar_cont)\n",
    "\n",
    "\n",
    "            for bar in bar_cont.find_elements(By.XPATH, './/div[contains(@class,\"mls-o-possession__average-intervals\")]'):\n",
    "                tip_id = bar.get_attribute('data-for')\n",
    "\n",
    "                tooltips = bar.find_elements(By.XPATH, './/div[contains(@class,\"__react_component_tooltip\")]')\n",
    "\n",
    "                tip = wait.until(EC.presence_of_element_located((By.ID, tip_id)))\n",
    "\n",
    "                spans = tip.find_elements(By.XPATH, './/span')\n",
    "\n",
    "                texts = [s.get_attribute('textContent').strip() for s in spans]\n",
    "                texts = [t for t in texts if t and t.upper() != 'SKIP TO MAIN CONTENT']\n",
    "\n",
    "                if len(texts) >= 4:\n",
    "                    home_poss, home_adv, away_poss, away_adv = texts[:4]\n",
    "                else:\n",
    "                    home_poss = home_adv = away_poss = away_adv = None\n",
    "\n",
    "                possession_stats.append({\n",
    "                    'tip_id': tip_id,\n",
    "                    'home_possession': home_poss,\n",
    "                    'home_advantage': home_adv,\n",
    "                    'away_possession': away_poss,\n",
    "                    'away_advantage': away_adv\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping possession stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            xg_mod_xpath = (\n",
    "                '//section[@data-toggle=\"clubs\" and not(contains(@style,\"display: none\"))]'\n",
    "                '//section[contains(@class,\"mls-l-module--expected-goals\")]'\n",
    "            )\n",
    "            xg_mod = wait.until(EC.visibility_of_element_located((By.XPATH, xg_mod_xpath)))\n",
    "\n",
    "            groups = xg_mod.find_elements(\n",
    "                By.CSS_SELECTOR,\n",
    "                '.mls-o-expected-goals__chart-group, .mls-o-expected-goals__club-group'\n",
    "            )\n",
    "            chart_group = next(\n",
    "                (g for g in groups if 'mls-o-expected-goals__chart-group' in (g.get_attribute('class') or '')),\n",
    "                None\n",
    "            )\n",
    "            if chart_group is None:\n",
    "                raise Exception(\"xG chart-group not found\")\n",
    "\n",
    "            # ensure cards exist\n",
    "            wait.until(lambda d: any(\n",
    "                e.is_displayed() for e in chart_group.find_elements(By.CSS_SELECTOR, '.mls-o-stat-chart')\n",
    "            ))\n",
    "\n",
    "            for card in chart_group.find_elements(By.CSS_SELECTOR, '.mls-o-stat-chart'):\n",
    "                header = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__header')\n",
    "                first  = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__first-value')\n",
    "                second = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__second-value')\n",
    "\n",
    "                stat_name  = (header.text or header.get_attribute('textContent') or '').strip()\n",
    "                home_value = (first.text  or first.get_attribute('textContent')  or '').strip()\n",
    "                away_value = (second.text or second.get_attribute('textContent') or '').strip()\n",
    "\n",
    "                xg_stats.append({\n",
    "                    'stat_name': stat_name,\n",
    "                    'home_value': home_value,\n",
    "                    'away_value': away_value\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping expected goals stats: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while scraping stats: {e}\")\n",
    "        pass\n",
    "\n",
    "    player_rows = []\n",
    "    gk_rows = []\n",
    "\n",
    "    try:\n",
    "        utils.js_scroll_by(driver, -3000)\n",
    "\n",
    "        player_btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.mls-o-buttons__segment[value=\"players\"]')))\n",
    "        player_btn.click()\n",
    "\n",
    "\n",
    "        players_mod = wait.until(EC.visibility_of_element_located((\n",
    "            By.XPATH,\n",
    "            '//section[contains(@class,\"mls-l-module--match-hub-player-stats\") and not(contains(@style,\"display: none\"))]'\n",
    "        )))\n",
    "\n",
    "        utils.js_scroll_into_view(driver, players_mod)\n",
    "\n",
    "        try:\n",
    "            teams = get_player_team_blocks(driver)\n",
    "        except Exception as e:\n",
    "            print(\"ERROR grouping team blocks:\", e)\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        player_rows = []\n",
    "        gk_rows = []\n",
    "\n",
    "\n",
    "        for idx, t in enumerate(teams):\n",
    "            side = \"home\" if idx == 0 else \"away\"\n",
    "\n",
    "            # parse main\n",
    "            for row in scrape_table(t[\"main\"]):\n",
    "                row.update({\"side\": side, \"club\": t[\"team\"], \"date\": date})\n",
    "                player_rows.append(row)\n",
    "\n",
    "            # parse gk\n",
    "            for row in scrape_table(t[\"gk\"]):\n",
    "                row.update({\"side\": side, \"club\": t[\"team\"], \"date\": date})\n",
    "                gk_rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while scraping player stats: {e}\")\n",
    "        \n",
    "    combined_rows = player_rows + gk_rows\n",
    "\n",
    "        \n",
    "    general_stats_df = pd.DataFrame(general_stats);  general_stats_df[\"category\"] = \"general\"\n",
    "    shooting_stats_df = pd.DataFrame(shooting_stats); shooting_stats_df[\"category\"] = \"shooting\"\n",
    "    passing_stats_df = pd.DataFrame(passing_stats);   passing_stats_df[\"category\"] = \"passing\"\n",
    "    possession_stats_df = pd.DataFrame(possession_stats); possession_stats_df[\"category\"] = \"possession\"\n",
    "    expected_goals_stats_df = pd.DataFrame(xg_stats); expected_goals_stats_df[\"category\"] = \"xg\"\n",
    "    player_stats_df = pd.DataFrame(combined_rows)\n",
    "\n",
    "    all_stats = pd.concat(\n",
    "        [general_stats_df, shooting_stats_df, passing_stats_df, possession_stats_df, expected_goals_stats_df],\n",
    "        axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "    player_stats_df['match_id'] = match_id\n",
    "    all_stats['match_id'] = match_id\n",
    "    player_stats_df['date'] = date\n",
    "    all_stats['date'] = date\n",
    "    return all_stats, player_stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd6e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_stats(driver, link):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    driver.get(link)\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        date = driver.find_element(\n",
    "            By.XPATH,\n",
    "            \"//div[contains(@class, 'mls-c-blockheader__subtitle')]\"\n",
    "        ).text.strip()\n",
    "    except:\n",
    "        date = None\n",
    "\n",
    "    try:\n",
    "        main_body = driver.find_element(By.TAG_NAME, 'main')\n",
    "        stats_bttn = main_body.find_element(By.LINK_TEXT, 'Stats')\n",
    "        stats_bttn.click()\n",
    "    except Exception as e:\n",
    "        print(\"Error clicking Stats:\", e)\n",
    "\n",
    "    try:\n",
    "        player_btn = wait.until(EC.element_to_be_clickable(\n",
    "            (By.CSS_SELECTOR, '.mls-o-buttons__segment[value=\"players\"]')\n",
    "        ))\n",
    "        player_btn.click()\n",
    "    except:\n",
    "        print(\"Could not click players button\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    time.sleep(1)\n",
    "    utils.js_scroll_by(driver, 1500)\n",
    "    time.sleep(1)\n",
    "\n",
    "    try:\n",
    "        teams = get_player_team_blocks(driver)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR grouping team blocks:\", e)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    player_rows = []\n",
    "    gk_rows = []\n",
    "\n",
    "\n",
    "    for idx, t in enumerate(teams):\n",
    "        side = \"home\" if idx == 0 else \"away\"\n",
    "\n",
    "        # parse main\n",
    "        for row in scrape_table(t[\"main\"]):\n",
    "            row.update({\"side\": side, \"club\": t[\"team\"], \"date\": date})\n",
    "            player_rows.append(row)\n",
    "\n",
    "        # parse gk\n",
    "        for row in scrape_table(t[\"gk\"]):\n",
    "            row.update({\"side\": side, \"club\": t[\"team\"], \"date\": date})\n",
    "            gk_rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(player_rows + gk_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30081012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_team_stats(driver, link, match_id):\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    driver.get(link)\n",
    "    \n",
    "    general_stats = []\n",
    "    shooting_stats = []\n",
    "    passing_stats = []\n",
    "    possession_stats = []\n",
    "    xg_stats = []\n",
    "    date = ''\n",
    "    home_team = ''\n",
    "    away_team = ''\n",
    "    \n",
    "    main_body = driver.find_element(By.TAG_NAME, 'main')\n",
    "    stats_bttn = main_body.find_element(By.LINK_TEXT, 'Stats')\n",
    "    \n",
    "    title_head = driver.find_element(By.CSS_SELECTOR,\n",
    "                                     \"section.mls-l-module--match-hub-header-container\"\n",
    "                                     )\n",
    "    teams = title_head.find_element(By.CSS_SELECTOR, 'div.mls-c-matchhub-tile')\n",
    "\n",
    "    try:\n",
    "        home_team = title_head.find_element(\n",
    "            By.CSS_SELECTOR,\n",
    "            \"div.mls-c-club.--home span.mls-c-club__shortname\"\n",
    "            ).text.strip()\n",
    "\n",
    "        away_team = title_head.find_element(\n",
    "            By.CSS_SELECTOR,\n",
    "            \"div.mls-c-club.--away span.mls-c-club__shortname\"\n",
    "        ).text.strip()\n",
    "        \n",
    "    except:\n",
    "        print(\"Could not extract team names.\")\n",
    "\n",
    "    try:\n",
    "        date = driver.find_element(By.XPATH, \"//div[contains(@class, 'mls-c-blockheader__subtitle')]\").text.strip()\n",
    "        stats_bttn.click()\n",
    "\n",
    "        try:\n",
    "            general_cont = wait.until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,\n",
    "                    '//section[contains(@class,\"mls-l-module--stats-comparison\")'\n",
    "                    ' and contains(@class,\"mls-l-module--general\")'\n",
    "                    ' and not(contains(@style,\"display: none\"))]')))\n",
    "\n",
    "\n",
    "            utils.js_scroll_into_view(driver, general_cont)\n",
    "            general_cards = utils.scrape_cards(general_cont, driver)\n",
    "\n",
    "            for it in general_cards:\n",
    "                general_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping general stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            clubs_wrap = wait.until(\n",
    "                EC.visibility_of_element_located((\n",
    "                    By.XPATH,\n",
    "                    '//section[contains(@class,\"d3-l-section-row\")][@data-toggle=\"clubs\" and not(contains(@style,\"display: none\"))]'\n",
    "                )))\n",
    "\n",
    "            shooting_cont = clubs_wrap.find_element(\n",
    "                By.XPATH,\n",
    "                './/section[contains(@class,\"mls-l-module--shooting-breakdown\")]'\n",
    "            )\n",
    "\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView({block:'center'});\",\n",
    "                shooting_cont)\n",
    "\n",
    "            shooting_cards = utils.scrape_cards(shooting_cont, driver)\n",
    "\n",
    "            for it in shooting_cards:\n",
    "                shooting_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping shooting stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            passing_cont = driver.find_element(By.XPATH, '//section[contains(@class,\"passing-breakdown\")]')\n",
    "\n",
    "            passing_cards = utils.scrape_cards(passing_cont, driver)\n",
    "            for it in passing_cards:\n",
    "                passing_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping passing stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            possession_cont = driver.find_element(By.XPATH, '//section[contains(@class,\"--possession\")]')\n",
    "            bar_cont = possession_cont.find_element(By.XPATH, './/*[contains(@class,\"mls-o-possession__intervals\")]')\n",
    "\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView({block:'center'});\",\n",
    "                bar_cont)\n",
    "\n",
    "\n",
    "            for bar in bar_cont.find_elements(By.XPATH, './/div[contains(@class,\"mls-o-possession__average-intervals\")]'):\n",
    "                tip_id = bar.get_attribute('data-for')\n",
    "\n",
    "                tooltips = bar.find_elements(By.XPATH, './/div[contains(@class,\"__react_component_tooltip\")]')\n",
    "\n",
    "                tip = wait.until(EC.presence_of_element_located((By.ID, tip_id)))\n",
    "\n",
    "                spans = tip.find_elements(By.XPATH, './/span')\n",
    "\n",
    "                texts = [s.get_attribute('textContent').strip() for s in spans]\n",
    "                texts = [t for t in texts if t and t.upper() != 'SKIP TO MAIN CONTENT']\n",
    "\n",
    "                if len(texts) >= 4:\n",
    "                    home_poss, home_adv, away_poss, away_adv = texts[:4]\n",
    "                else:\n",
    "                    home_poss = home_adv = away_poss = away_adv = None\n",
    "\n",
    "                possession_stats.append({\n",
    "                    'tip_id': tip_id,\n",
    "                    'home_possession': home_poss,\n",
    "                    'home_advantage': home_adv,\n",
    "                    'away_possession': away_poss,\n",
    "                    'away_advantage': away_adv\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping possession stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            xg_mod_xpath = (\n",
    "                '//section[@data-toggle=\"clubs\" and not(contains(@style,\"display: none\"))]'\n",
    "                '//section[contains(@class,\"mls-l-module--expected-goals\")]'\n",
    "            )\n",
    "            xg_mod = wait.until(EC.visibility_of_element_located((By.XPATH, xg_mod_xpath)))\n",
    "\n",
    "            groups = xg_mod.find_elements(\n",
    "                By.CSS_SELECTOR,\n",
    "                '.mls-o-expected-goals__chart-group, .mls-o-expected-goals__club-group'\n",
    "            )\n",
    "            chart_group = next(\n",
    "                (g for g in groups if 'mls-o-expected-goals__chart-group' in (g.get_attribute('class') or '')),\n",
    "                None\n",
    "            )\n",
    "            if chart_group is None:\n",
    "                raise Exception(\"xG chart-group not found\")\n",
    "\n",
    "            # ensure cards exist\n",
    "            wait.until(lambda d: any(\n",
    "                e.is_displayed() for e in chart_group.find_elements(By.CSS_SELECTOR, '.mls-o-stat-chart')\n",
    "            ))\n",
    "\n",
    "            for card in chart_group.find_elements(By.CSS_SELECTOR, '.mls-o-stat-chart'):\n",
    "                header = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__header')\n",
    "                first  = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__first-value')\n",
    "                second = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__second-value')\n",
    "\n",
    "                stat_name  = (header.text or header.get_attribute('textContent') or '').strip()\n",
    "                home_value = (first.text  or first.get_attribute('textContent')  or '').strip()\n",
    "                away_value = (second.text or second.get_attribute('textContent') or '').strip()\n",
    "\n",
    "                xg_stats.append({\n",
    "                    'stat_name': stat_name,\n",
    "                    'home_value': home_value,\n",
    "                    'away_value': away_value\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping expected goals stats: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while scraping stats: {e}\")\n",
    "        pass\n",
    "\n",
    "        \n",
    "    general_stats_df = pd.DataFrame(general_stats);  general_stats_df[\"category\"] = \"general\"\n",
    "    shooting_stats_df = pd.DataFrame(shooting_stats); shooting_stats_df[\"category\"] = \"shooting\"\n",
    "    passing_stats_df = pd.DataFrame(passing_stats);   passing_stats_df[\"category\"] = \"passing\"\n",
    "    possession_stats_df = pd.DataFrame(possession_stats); possession_stats_df[\"category\"] = \"possession\"\n",
    "    expected_goals_stats_df = pd.DataFrame(xg_stats); expected_goals_stats_df[\"category\"] = \"xg\"\n",
    "    \n",
    "    all_stats = pd.concat(\n",
    "        [general_stats_df, shooting_stats_df, passing_stats_df, possession_stats_df, expected_goals_stats_df],\n",
    "        axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "    all_stats['match_id'] = match_id\n",
    "    all_stats['date'] = date\n",
    "    all_stats['home_team'] = home_team\n",
    "    all_stats['away_team'] = away_team\n",
    "    return all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e39cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_df(x):\n",
    "    if isinstance(x, list):\n",
    "        return pd.DataFrame(x)\n",
    "    elif isinstance(x, dict):\n",
    "        return pd.DataFrame([x])\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57fa7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch(i, teams, players, feed, remaining_links):\n",
    "    print(f\"[save] batch up to {i}, {len(remaining_links)} left\")\n",
    "    \n",
    "    print(\"players type:\", type(players))\n",
    "    print(\"teams type:\", type(teams))\n",
    "    print(\"feed type:\", type(feed))\n",
    "\n",
    "    if isinstance(players, list):\n",
    "        if players:\n",
    "            print(\"players[0] type:\", type(players[0]))\n",
    "        else:\n",
    "            print(\"players is an empty list\")\n",
    "\n",
    "    if isinstance(teams, list):\n",
    "        if teams:\n",
    "            print(\"teams[0] type:\", type(teams[0]))\n",
    "        else:\n",
    "            print(\"teams is an empty list\")\n",
    "\n",
    "    if isinstance(feed, list):\n",
    "        if feed:\n",
    "            print(\"feed[0] type:\", type(feed[0]))\n",
    "        else:\n",
    "            print(\"feed is an empty list\")\n",
    "\n",
    "    ensure_df(players).to_csv(\n",
    "        f\"../../data_files/scraped_raw/matches/players/latest_player_stats_batch_{i}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    ensure_df(teams).to_csv(\n",
    "        f\"../../data_files/scraped_raw/matches/teams/latest_team_stats_batch_{i}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    ensure_df(feed).to_csv(\n",
    "        f\"../../data_files/scraped_raw/matches/feed/latest_match_feed_batch_{i}.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    with open(\"remaining_links.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in remaining_links:\n",
    "            f.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5340669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_single_match(match_id, stats, player_stats, feed):\n",
    "    stats.to_csv(f\"../../data_files/scraped_raw/matches/teams/stats_{match_id}.csv\", index=False)\n",
    "    player_stats.to_csv(f\"../../data_files/scraped_raw/matches/players/player_stats_{match_id}.csv\", index=False)\n",
    "    feed.to_csv(f\"../../data_files/scraped_raw/matches/feed/feed_{match_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_match_id(link):\n",
    "    if (\n",
    "        link is None\n",
    "        or (isinstance(link, float) and math.isnan(link))\n",
    "        or str(link).strip() == ''\n",
    "        or str(link).strip().lower() == 'nan'\n",
    "    ):\n",
    "        return None\n",
    "\n",
    "    return hashlib.md5(\n",
    "        link.rstrip('/').split('/')[-1].split('?')[0].encode('utf-8')\n",
    "    ).hexdigest()[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_match_data(links, driver, batch_size=25):\n",
    "    latest_stats = []\n",
    "    latest_player_stats = []\n",
    "    latest_feed = []\n",
    "\n",
    "    remaining_links = list(links)\n",
    "    \n",
    "    processed = 0\n",
    "\n",
    "    for link in list(remaining_links):\n",
    "        processed += 1\n",
    "        print(f\"[{processed}] Processing: {link}\")\n",
    "\n",
    "        if pd.isna(link) or not str(link).strip():\n",
    "            print(\"[skip] invalid link\")\n",
    "            remaining_links.remove(link)\n",
    "            continue\n",
    "        \n",
    "        match_id = create_match_id(link)\n",
    "\n",
    "        try: \n",
    "            feed = extract_feed(driver, link, match_id)\n",
    "            stats, player_stats = extract_stats(driver, link, match_id)\n",
    "            \n",
    "            remaining_links.remove(link)\n",
    "\n",
    "            save_single_match(\n",
    "            match_id,\n",
    "            add_match_id(stats, match_id),\n",
    "            add_match_id(player_stats, match_id),\n",
    "            add_match_id(feed, match_id)\n",
    "        )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing link {link}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # batch save\n",
    "        if processed % batch_size == 0:\n",
    "            save_batch(processed, latest_stats, latest_player_stats, latest_feed, remaining_links)\n",
    "            latest_stats.clear()\n",
    "            latest_player_stats.clear()\n",
    "            latest_feed.clear()\n",
    "            \n",
    "            with open(\"remaining_links.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                for l in remaining_links:\n",
    "                    f.write(str(l) + \"\\n\")\n",
    "\n",
    "    # save final leftovers\n",
    "    if latest_stats:\n",
    "        save_batch(processed, latest_stats, latest_player_stats, latest_feed, remaining_links)\n",
    "        \n",
    "    with open(\"remaining_links.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for l in remaining_links:\n",
    "            f.write(str(l) + \"\\n\")\n",
    "\n",
    "    driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d67c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_match_player_data(driver, match_id):\n",
    "    \n",
    "    latest_player_stats = []\n",
    "\n",
    "        if pd.isna(link) or not str(link).strip():\n",
    "            print(\"[skip] invalid link\")\n",
    "            remaining_links.remove(link)\n",
    "            continue\n",
    "\n",
    "        try: \n",
    "            player_stats = extract_player_stats(driver, link)\n",
    "            \n",
    "            latest_player_stats.append(player_stats)\n",
    "            \n",
    "            remaining_links.remove(link)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing link {link}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # batch save\n",
    "        if processed % batch_size == 0:\n",
    "            save_batch(processed, latest_player_stats, remaining_links)\n",
    "            latest_player_stats.clear()\n",
    "            \n",
    "            with open(\"remaining_links.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                for l in remaining_links:\n",
    "                    f.write(str(l) + \"\\n\")\n",
    "\n",
    "    # save final leftovers\n",
    "    if latest_player_stats:\n",
    "        save_batch(processed, latest_player_stats, remaining_links)\n",
    "        \n",
    "    with open(\"remaining_links.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for l in remaining_links:\n",
    "            f.write(str(l) + \"\\n\")\n",
    "\n",
    "    driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f2ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_links():\n",
    "    if os.path.exists(\"remaining_links.txt\"):\n",
    "        print(\"[resume] Loading remaining links...\")\n",
    "        with open(\"remaining_links.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            return [line.strip() for line in f if line.strip()]\n",
    "    else:\n",
    "        print(\"[fresh start] No remaining_links.txt found, loading from CSV...\")\n",
    "        df = pd.read_csv('../../data_files/scraped_raw/mls_match_links.csv')\n",
    "        return df[\"Match Links\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2384d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = set_up_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b8810d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resume] Loading remaining links...\n"
     ]
    }
   ],
   "source": [
    "links_list = load_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "529fa436",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/2024/matches/nevsstl-09-07-2024 link # 1 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/undefined/matches/nshvsrsl-04-12-2025 link # 2 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/2024/matches/miavscin-08-24-2024 link # 3 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/2024/matches/nycvsclt-04-27-2024 link # 4 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/undefined/matches/atlvsdal-04-05-2025 link # 5 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/2024/matches/miavsnsh-04-20-2024 link # 6 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/undefined/matches/rbnyvsdc-04-19-2025 link # 7 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/undefined/matches/colvsla-06-25-2025 link # 8 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/2024/matches/nevsclt-04-06-2024 link # 9 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/2024/matches/atlvstor-06-29-2024 link # 10 of 11\n",
      "Scraping: https://www.mlssoccer.com/competitions/mls-regular-season/2024/matches/clbvsorl-09-21-2024 link # 11 of 11\n",
      "Saved team_stats_combined.csv with 638 rows\n"
     ]
    }
   ],
   "source": [
    "all_stats = []\n",
    "\n",
    "for link in links_list:\n",
    "    try:\n",
    "        print(\"Scraping:\", link, \"link #\", links_list.index(link) + 1, \"of\", len(links_list))\n",
    "        df = extract_team_stats(driver, link, None)  \n",
    "        if df is not None and not df.empty:\n",
    "            all_stats.append(df)\n",
    "        else:\n",
    "            print(\"No data for:\", link)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on {link}: {e}\")\n",
    "\n",
    "# combine\n",
    "big_df = pd.concat(all_stats, ignore_index=True)\n",
    "\n",
    "# save to a single CSV\n",
    "big_df.to_csv(\"team_stats_combined2.csv\", index=False)\n",
    "\n",
    "print(\"Saved team_stats_combined.csv with\", len(big_df), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_match_player_data(links_list, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e85fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_match_data(links_list, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f7a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### combine data into three csv files: team stats, player stats, match feeds\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# find all csv files in the working directory\n",
    "csvs = glob.glob(\"../../data_files/scraped_raw/matches/**/*.csv\", recursive=True)\n",
    "\n",
    "output_team = \"../../data_files/scraped_raw/matches/teams/mls_match_team_stats.csv\"\n",
    "output_player = \"../../data_files/scraped_raw/matches/players/mls_match_player_stats.csv\"\n",
    "output_feed = \"../../data_files/scraped_raw/matches/feed/mls_match_feeds.csv\"\n",
    "\n",
    "for csv_file in csvs:\n",
    "    # skip the combined output files to avoid re-reading/appending them\n",
    "    if csv_file in (output_team, output_player, output_feed):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {csv_file}: failed to read ({e})\")\n",
    "        continue\n",
    "\n",
    "    fname = csv_file.lower()\n",
    "    if \"player_stats\" in fname:\n",
    "        df.to_csv(output_player, mode=\"a\", index=False, header=not os.path.exists(output_player))\n",
    "    elif \"stats\" in fname:\n",
    "        df.to_csv(output_team, mode=\"a\", index=False, header=not os.path.exists(output_team))\n",
    "    elif \"feed\" in fname:\n",
    "        df.to_csv(output_feed, mode=\"a\", index=False, header=not os.path.exists(output_feed))\n",
    "    else:\n",
    "        # optional: handle or log files that don't match expected patterns\n",
    "        print(f\"Ignored {csv_file}: no matching target\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
